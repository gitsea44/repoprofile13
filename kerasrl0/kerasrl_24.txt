{'dependent': 'kerasrl', 'repo': '/TheTrash/Thesis-Work', 'language': 'Jupyter Notebook', 'description': 'My final work for my degree in computer science', 'readme': '**Tesi Mattia Polticchia**\n---\n---\n\nÈ stato deciso di abbandonare la librearia keras-rl perché causava parecchi problemi nello sviluppo del progetto.\nAttualmente si è passati a Stable-Baseline.\n\nPresentazione\n---\nGit fatto per il versioning dei file della tesi.\nL\'argomento della tesi è la creazione di un\'intelligenza artificiale che tramite il reinforcement learning impari a giocare a tetris.\nIl punto focale è riuscire a farle imparare a giocare dandole delle limitate informazioni sull\'ambiente.\nL\'ambiente utilizzato è sviluppato tramite OpenAI e si chiama gym-tetris\na cui sono state applicate alcune modifiche per aumentare la compatibilità con l\'AI. \nL\'AI è stata implementata in Keras-rl libreria sviluppata tramite Keras contentente i principali algoritmi di apprendimento per RL.\n\nI dati che vengono passati all\'Agente dopo ogni step sono:\n### *observation / state*\nSemplificazione delle righe della "mappa"\n\n### *reward*\nnumerical reward given after some valuable actions. Like rows. \n\n\n### *done*\nBool value that represent if the play is finished or not\n\n### *Info*\nKey |\tType |\tDescription\n----|--------|-------------\n`current_piece`   | `str` | pezzo corrente come stringa\n`number_of_lines` | `int` |\tnumero delle linee fatte\n`score`           | `int` |\tpunteggio corrente\n`next_piece`      | `str` |\tprossimo pezzo\n`statistics`     | `dict`|\tstatistica dei pezzi\n\n\n\nBug e problemi\n---\n## Rivisitazione progettuale:\nL\'unico problema si ha con l\'uso di tensorboard che appesantisce di molto l\'esecuzione.\nPer ora si stanno facendo i learn senza utilizzarlo. I dati principali vengono salvati su un file di testo ogni 100k di step.\n\n### Problemi passati: \n`[Tensorflow 2.0] AttributeError: Tensor.op is meaningless when eager execution is enabled`\nUna possibile soluzione è questo `train_interval=4` messo nella creazione dell\' DQNAgent.\n\nÈ stata aperta un\' issue sul git della libreria [keras-rl2](https://github.com/wau/keras-rl2/issues/7).\nSi verifica che l\'agente con dei nodi Conv2D ( _Convoluzionali a 2 dimensioni_ ) aggiunge inspiegabilmete un layer e la rete non riconosce l\'input shape.\n\nAggiunta:\n> Consultare le [issues](https://github.com/wau/keras-rl/issues]) e le [pull](https://github.com/keras-rl/keras-rl/pulls) per avere aiuto nella soluzione dei problemi.\n\nModifiche nel tempo\n---\n* Cambiata la policy dopo una selezione fatta seguendo un articolo su un sito \nspecialistico.\n\n* Rimossi alcuni parametri nella creazione dell\' oggetto DQNAgent perché superflui in quanto già presenti nella dichiarazione dalla classe. Ha senso metterli solo  se si vogliono diversi valori rispetto agli standard. \n\n* Si è deciso di passare ad una rete neurale così formata: //inserire immagine.\nPerché probabilmente alla rete viene passata anche l\'attuale disposzione dei tetrimini e quindi è più probabile che l\'elaborazione migliori notevolmente. \n\n* È stata aggiunta parecchia documentazione proveniente da vari link e alcuna scritta da me in modo da avere del materiale da poter utilizzare e studiare.\n\nRete neurale\n---\n* Aggiunto il valore di dropout per evitare l\'overfitting. Questo ha effettivamente portato a dei miglioramenti in tempo e in quantità di punti.\nI nodi sono stati attualmente omessi per il cambio dell\'architettura della rete. Verranno riaggiunti appena il problema sarà risolto.\n\n* Modificata la struttura dei nodi e la dichiarazione dell\'attivatore\n\nfrom :\n```\nagent.add(Dense(16))\nagent.add(Activation(\'relu\'))\n```\nto : \n\n `model.add(Dense(16, activation=\'relu\'))`\n\nTetris Env\n---\nIl tetris ENV è stato omesso da questo git per comodità di manutenzione ma i file che sono stati modificati sono presenti nella cartella Env assieme ad un piccolo file che ne spiega le modifiche.', 'contents': "['AI', 'README.md', 'ipynb', 'assets', 'docs', 'env', 'requirements.txt']", 'stars': 0, 'watchers': 0, 'forks': 0, 'deprepos': 0, 'deppacks': 0}