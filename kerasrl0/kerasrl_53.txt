{'dependent': 'kerasrl', 'repo': '/mjuchli/ctc-executioner', 'language': 'Jupyter Notebook', 'description': 'Master Thesis: Limit order placement with Reinforcement Learning ', 'readme': '# Order placement with Reinforcement Learning \n\nCTC-Executioner is a tool that provides an on-demand execution/placement strategy for limit orders on crypto currency markets using Reinforcement Learning techniques. The underlying framework provides functionalities which allow to analyse order book data and derive features thereof. Those findings can then be used in order to dynamically update the decision making process of the execution strategy.\n\nThe methods being used are based on a research project (master thesis) currently proceeding at TU Delft.\n\n## Documentation\n\nComprehensive documentation and concepts explained in the [academic report](https://github.com/backender/ctc-executioner/blob/master/docs/report.pdf)\n\nFor hands-on documentation and examples see [Wiki](https://github.com/backender/ctc-executioner/wiki)\n\n## Usage\n\nLoad orderbooks\n\n```python\norderbook = Orderbook()\norderbook.loadFromEvents(\'data/example-ob-train.tsv\')\norderbook.summary()\norderbook.plot(show_bidask=True)\n\norderbook_test = Orderbook()\norderbook_test.loadFromEvents(\'data/example-ob-test.tsv\')\norderbook_test.summary()\n```\n\nCreate and configure environments\n\n```python\nimport gym_ctc_executioner\nenv = gym.make("ctc-executioner-v0")\nenv.setOrderbook(orderbook)\n\nenv_test = gym.make("ctc-executioner-v0")\nenv_test.setOrderbook(orderbook_test)\n```\n', 'contents': "['.gitignore', 'README.md', 'agent_baseline.py', 'agent_baseline_backtest.py', 'agent_dqn.py', 'agent_keras_rl.py', 'agent_qlearn.py', 'ctc_executioner', 'data', 'docs', 'gym_ctc_executioner', 'gym_ctc_marketmaker', 'images', 'notebooks', 'report', 'requirements.txt', 'setup.py', 'strategy.py']", 'stars': 86, 'watchers': 86, 'forks': 39, 'deprepos': 'zero', 'deppacks': 'zero'}