{'dependent': 'kerasrl', 'repo': '/skipperkongen/lunar-lander-rl', 'language': 'Python', 'description': 'Lunar Lander (OpenAI Gym) with a DQN Agent from keras-rl', 'readme': '# Lunar Lander with keras-rl\n\nI have trained an agent that runs the [Deep Q-Learning](https://towardsdatascience.com/self-learning-ai-agents-part-ii-deep-q-learning-b5ac60c3f47) algorithm (DQNAgent from `keras-rl`) to learn the Lunar Lander reinforcement environment from Open AI Gym.\n\nThe brains of the agent is a deep neural network with three fully-connected hidden layers. The neural net is implemented in Keras, which is\nthe logical choice in combination with the `keras-rl` library for reinforcement learning.\n\nDependencies:\n\n- Python3\n- OpenAI Gym: `pip install gym`\n- Tensorflow: `pip install tensorflow`\n- Keras: `pip install keras`\n- Keras RL: `pip install keras-rl`\n- Box2D (I think): `pip install box2d-py`\n- h5py (I think): `pip install h5py`\n\nI\'m not 100% sure of all the dependencies, but it\'s in the ballpark.\n\n## Run the pretrained agent\n\nYou can test the pretrained agent (and your own agent if you ran the trained one) with:\n\n```\npython lunar-dqn-test.py\n```\n\nThis script first runs an untrained agent for 5 episodes and then the pretrained agent for 5 episodes. The purpose is that you can see the difference before and after training.\n\nHere is a video that shows the expected output (first sequence untrained, second sequence after training).\n\n<iframe width="560" height="315" src="https://www.youtube.com/embed/Nc1EsqCuUsE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>\n\nThe test scripts automatically tries to load a weight weights file called `dqn_lunarlander-v2_weights.m5f`, which will be produced by the training script (see below). If that fails, the script loads a weights file called `dqn_lunarlander-v2_weights_20190321.m5f` that should already exist in this repository. The weights file contains weights for the deep neural network mentioned above.\n\n## Train the agent from scratch\n\nYou can also train the agent from scratch. You tell the script how many decision you will train the agent on, for example 10000 decisions.\n\n```\npython lunar-dqn-train.py 10000\n```\n\nThe output of the script is a file called `dqn_lunarlander-v2_weights.m5f`. If this file exists, then the test script (see above) will use those weights instead of the default.\n\nIf you repeatedly run the training script, the script will first load the previous weights (if they exist) and then resume training from that point.\n', 'contents': "['README.md', 'dqn_lunarlander-v2_weights_20190321.h5f', 'lunar-dqn-test.py', 'lunar-dqn-train.py', 'requirements.txt']", 'stars': 0, 'watchers': 0, 'forks': 0, 'deprepos': 0, 'deppacks': 0}