{'dependent': 'kerasrl', 'repo': '/comnetsAD/autoComparisonTool', 'language': 'Jupyter Notebook', 'description': None, 'readme': '# JSCleaner:  Analysis of different versions of index\n\n## 1. Structural Comparison\n\n### i) Screenshots of the entire page.\n\nFor taking screenshots of the entire page, Selenium was used. First the selenium driver was run and the page was scrolled to the bottom, a wait was added for the page to load and the height was noted and stored. Then, a headless driver was run with the stored height and constant width (1920px).\n\n    options.add_argument("--headless")\n    options.add_argument("--window-size=1920,{height}")\n    options.add_argument("--hide-scrollbars")\n\nAfter this the screenshots were saved using the built in selenium function:\n\n    driver.save_screenshot(Path)\n\n### ii) Similarity Scores\n\nFor the comparison, two methods were used: sklearn\'s SSIM index and the mean squared error. Mean squared error is defined as the sum of the squared difference between the two images as shown below.\n\n<p align = "center">\n<img src = "https://latex.codecogs.com/gif.latex?MSE&space;=&space;\\frac{1}{mn}&space;\\sum_{i=0}^{m-1}&space;\\sum_{j=0}^{n-1}&space;\\left[I(i,j)-K(i,j)&space;\\right]^2" />\n</p>\n\n    def mse(imageA, imageB):\n        err = np.sum((imageA.astype("float") - imageB.astype("float")) ** 2)\n        err /= float(imageA.shape[0] * imageA.shape[1])\n        return err\n\nFor both of these to work, the images must have the same dimensions since both of these scores are based on pixel by pixel calculations.\n\n## Functional Comparison\n\n### a. Screenshots.\n\nFor the first step, all the Classes and IDs were extracted. To do this, the source code from Selenium was passed through a parser based on beautifulsoup\n\n    soup = bs(driver.page_source.encode("utf-8"),"lxml")\n\nAfter this, functions from beautifulsoup were used to extract all the Classes and IDs using `tag.get(\'id\')`\n\nUsing this all the tags and their corresponding IDs/Classes were stored in a list.\n\nNow selenium was used to loop over the list and to (a) scroll to the part of the page where the tag with a particular ID/class in the list exists, (b) hover over the tag, and (c) take a screenshot of it.\n\n\n    # find element in the code\n    elem = driver.find_element_by_id(id[1])\n\n    # get y position and scroll to that location\n    location = elem.location.get(\'y\')\n    scrollScript = "setTimeout(function(){window.scrollTo(0," + str(location) + ");}, 2000);"\n    driver.execute_script(scrollScript)\n    time.sleep(.5)\n\n    # hover over that element\n    actions = ActionChains(driver)\n    driver.execute_script("arguments[0].scrollIntoView();", elem)\n    actions.move_to_element(elem)\n    actions.perform()\n\n    # hover over that element\n\t\tdriver.save_screenshot(Path)\n\n### b. Similarity Scores\n\nNow that I had the screenshots for every tag hovered over I had to separate the components. For this, i did the following:\n\n#### i. Normalisation of the image\n\nThe image was converted from 3 dimensional numpy array that stored an RGB color map across the 2 dimensional pixel map to a 2 dimensional numpy array that stored 0 wherever the background was (White // 255, 255, 255 in most cases) and everything else was replaced with 1.\n\n    for i in range(len(img)):\n        for j in range(len(img[0])):\n            if list(img[i][j]) == background:\n                img[i][j] = black\n                l+=1\n            else:\n                img[i][j] = white\n                k+=1\n\n<p align = "center">\n<img src = "readme01.png" width=450px />\n<p>\n\nI tried using the builtin thresholding methods in openCV initially but the results were not as good as it were using the above mentioned technique\n\n#### ii. Breaking into Components\n\nTo break these into components, I first used skImage’s dilate function which thickens all the white clusters. A 15x15 kernel was generally used but it was altered depending on the website.\nmask = cv2.dilate (img2Mask,np.ones((15, 15)))\n\nThen, I used OpenCV’s Connected Components to extract disconnected components after dilation\nlablels, markers = cv2.connectedComponents(mask, connectivity=8)\n\nFollowing is an example of how a component looks\n\n<p align = "center">\n<img src = "readme02.png" width=270px />\n<p>\n\n#### iii. Cropping the Components\n\nImage was cropped using contours maps but when saved the original image was used.\n\n    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    _,thresh = cv2.threshold(gray,1,255,cv2.THRESH_BINARY)\n    contours = [cv2.findContours(thresh,cv2.RETR_EXTERNAL)]\n    cnt = contours[0][0]\n    x,y,w,h = cv2.boundingRect(cnt)\n\n    crop = (cv2.imread (loc))[y:y+h,x:x+w]\n\nThis is an example of a cropped component\n\n<p align = "center">\n<img src = "readme03.png" width=270px />\n<p>\n\n#### iv. Using image integrals to find components\nImage integrals were used to search components within the images.\n\n<p align = "center">\n<img src = "readme04.png" width=500px />\n<p>\n\n    def find_image(im, tpl):\n        im = np.atleast_3d(im)\n        tpl = np.atleast_3d(tpl)\n        H, W, D = im.shape[:3]\n        h, w = tpl.shape[:2]\n\n        # Integral image and template sum per channel\n        sat = im.cumsum(1).cumsum(0)\n        tplsum = np.array([tpl[:, :, i].sum() for i in range(D)])\n\n        # Calculate lookup table for all the possible windows\n        iA, iB, iC, iD = sat[:-h, :-w], sat[:-h, w:], sat[h:, :-w], sat[h:, w:]\n        lookup = iD - iB - iC + iA\n\n        # Possible matches\n        possible_match = np.where(np.logical_and.reduce([lookup[..., i] == tplsum[i] for i in range(D)]))\n\n        # Find exact match\n        for y, x in zip(*possible_match):\n            if np.all(im[y+1:y+h+1, x+1:x+w+1] == tpl):\n                return (y+1, x+1)\n\n        return False\n\n\nThe x,y coordinates were returned, the rectangles were drawn on the original screenshot to show the location of the matches and the score was marked `True`, otherwise if the component was not found, `False` was returned for all such components that were not found, they were compared against all components of the original index.html using Structural similarity index and if a match was found, The score was marked `True`. At the end the score was calculated.\n\n\n<p align = "center">\n<img src = "readme05.png" width=500px />\n<p>\n\n\n    \n', 'contents': "['Comparison', 'readme.md', 'readme01.png', 'readme02.png', 'readme03.png', 'readme04.png', 'readme05.png']", 'stars': 0, 'watchers': 0, 'forks': 0, 'deprepos': 0, 'deppacks': 0}