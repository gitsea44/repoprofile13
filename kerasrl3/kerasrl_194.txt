{'dependent': 'kerasrl', 'repo': '/AlmightyYakob/deep_slither', 'language': 'Python', 'description': 'A project to train a Neural Network to play Slither.io using Reinforcement Learning', 'readme': '# Training a Neural Network to play [Slither.io](http://slither.io) using Reinforcement Learning\n\n## Requirements\n* [Selenium chromedriver](https://sites.google.com/a/chromium.org/chromedriver/downloads)\n* Tensorflow (may need to roll back from 2.0.0 to 2.0.0-beta, due to keras-rl reqs)\n\n\n## Resources\n* [Not working example but has some reference code](https://botfather.io/docs/wizard/simple-agario-bot-tutorial/)\n* [Example use of Selenium](https://automatetheboringstuff.com/chapter11/)\n* [Specific part of Selenium documentation, highlighting important functions](https://selenium.dev/selenium/docs/api/py/webdriver_remote/selenium.webdriver.remote.webdriver.html?highlight=get_screenshot#selenium.webdriver.remote.webdriver.WebDriver.get_screenshot_as_file)\n* [Agario driver that uses selenium](https://github.com/gsgalloway/agar-io-driver)\n* [Article on DDQNs](https://www.freecodecamp.org/news/improvements-in-deep-q-learning-dueling-double-dqn-prioritized-experience-replay-and-fixed-58b130cc5682/)\n* [Actor-Critic](https://sergioskar.github.io/Actor_critics/)\n* [Repo with an implementation of A3C](https://github.com/germain-hug/Deep-RL-Keras)\n\n\n## TODO\n* [x] Add action handling in env.step\n* [x] Add image processing to observation (convert to np.array)\n* [x] Find A3C implementation to use\n* [ ] Use env with A3C model\n', 'contents': "['.env', '.flake8', '.gitignore', 'Pipfile', 'Pipfile.lock', 'README.md', 'agario.py', 'constants.py', 'conv_visualize.py', 'gym-io', 'models.py', 'slither.py', 'test_slither.py']", 'stars': 1, 'watchers': 1, 'forks': 0, 'deprepos': 0, 'deppacks': 0}