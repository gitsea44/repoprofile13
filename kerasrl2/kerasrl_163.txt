{'dependent': 'kerasrl', 'repo': '/pjhool/TF-A2RL-Test', 'language': 'Python', 'description': 'A2RL-Test', 'readme': "# TF-A2RL: Automatic Image Cropping\n[[Project]](https://debangli.github.io/A2RL/)   [[Paper]](https://arxiv.org/abs/1709.04595)   [[Online Demo]](https://wuhuikai.github.io/TF-A2RL/)    [[API]](https://algorithmia.com/algorithms/wuhuikai/A2RL_online)   [[Related Work: GP-GAN (for Image Blending)]](https://github.com/wuhuikai/GP-GAN)\n\nThe official implementation for A2-RL: Aesthetics Aware Rinforcement Learning for Automatic Image Cropping\n\n## Overview\n\n| source | step 1 | step 2 | step 3 | step 4 | step 5 | output| \n| --- | --- | --- | --- | --- | --- | --- |\n| ![](images/readme/source.png) | ![](images/readme/step1.png) | ![](images/readme/step2.png) | ![](images/readme/step3.png) | ![](images/readme/step4.png) | ![](images/readme/step5.png) | ![](images/readme/output.png) |\n\nA2-RL (aka. Aesthetics Aware Reinforcement Learning) is the author's implementation of the RL-based automatic image cropping algorithm described in:\n```\nA2-RL: Aesthetics Aware Reinforcement Learning for Automatic Image Cropping   \nDebang Li, Huikai Wu, Junge Zhang, Kaiqi Huang\n```\n\nGiven a source image, our algorithm could take actions step by step to find almost the best cropping window on source image. \n\nContact: Hui-Kai Wu (huikaiwu@icloud.com)\n\n## View Finding Network\nEvaluation\nWe provide the evaluation script to reproduce our evaluation results on Flickr cropping dataset. For example,\n\n$ python vfn_eval.py --spp false --snapshot snapshots/model-wo-spp\nYou will need to get sliding_window.json and the test images from the Flickr cropping dataset and specify the path of your model when running vfn_eval.py. You can also try our pre-trained model, which can be downloaded from [[here]]( https://drive.google.com/drive/folders/0B0sDVRDPL5zBd3ozNlFmZEZpY1k).\n\nCopy pre-trained model to View_Finding Direcotry \n\nIf you want to get an aesthetic score of a patch, please take a look at the example featured by [[ModelDepot]]( https://modeldepot.io/yilingchen/view-finding-network ) \n\n## Getting started\n* Install the python libraries. (See `Requirements`).\n* Download the code from GitHub:\n```bash\ngit clone https://github.com/pjhool/TF-A2RL-Test.git\ncd TF-A2RL-Test\n```\n* Download the pretrained models `vfn_rl.pk` from [Google Drive](https://drive.google.com/open?id=0Bybnpq8dvwudREJnRWhFbk1rYW8), then put them in current directory (`TF-A2RL/`).\n\n* Run the python script:\n``` bash\npython A2RL.py --image_path ./test_images --save_path ./test_images_cropped\n```\nor\n``` bash\nsh example.sh\n```\n* To A2RL Test for  AVA Landscape Images , download  [AVA Landscape Images ]( https://drive.google.com/open?id=1ojdHxuW8L10hjafwbMIJAAJsD6PYm8yU ) \n   \n\n\n## Results compared with baseline methods (more [results](https://debangli.github.io/A2RL/))\n\n|Source| VFN+Sliding window | A2-RL | Ground Truth |\n| --- | --- | --- |---|\n| ![](images/readme/1227.jpg) | ![](images/readme/vfn_1227.jpg) | ![](images/readme/a2rl_1227.jpg) | ![](images/readme/gt_1227.jpg) |\n| ![](images/readme/1644.jpg) | ![](images/readme/vfn_1644.png) | ![](images/readme/output.png) | ![](images/readme/gt_1644.jpg) |\n| ![](images/readme/2747.jpg) | ![](images/readme/vfn_2747.jpg) | ![](images/readme/a2rl_2747.jpg) | ![](images/readme/gt_2747.jpg) |\n| ![](images/readme/2903.jpg) | ![](images/readme/vfn_2903.jpg) | ![](images/readme/a2rl_2903.jpg) | ![](images/readme/gt_2903.jpg) |\n| ![](images/readme/9036.jpg) | ![](images/readme/vfn_9036.jpg) | ![](images/readme/a2rl_9036.jpg) | ![](images/readme/gt_9036.jpg) |\n\n## Requirements\nThe code requires the following 3rd party libraries:\n* pickle\n* numpy\n* [skimage](http://scikit-image.org/)\n```bash\npip install scikit-image\n```\nDetails see the official [README](https://github.com/scikit-image/scikit-image) for installing skimage.\n* [TensorFlow](https://www.tensorflow.org/) 1.4 \n\nDetails see the official [README](https://github.com/tensorflow/tensorflow) for installing TensorFlow. \n## Command line arguments:\nType `python A2RL.py --help` for a complete list of the arguments.\n* `--image_path`: path of the input image\n* `--save_path`: path of output image\n## Citation\n```\n@article{li2017a2,\n  title={A2-RL: Aesthetics Aware Reinforcement Learning for Automatic Image Cropping},\n  author={Li, Debang and Wu, Huikai and Zhang, Junge and Huang, Kaiqi},\n  journal={arXiv preprint arXiv:1709.04595},\n  year={2017}\n}\n```\n", 'contents': "['.gitignore', '.idea', 'A2RL.py', 'LICENSE', 'README.md', '__init__.py', 'a2rl_test.csv', 'a2rl_test_Landscape.csv', 'actions.py', 'example.sh', 'images', 'network.py', 'paper', 'requirements.txt', 'test_images', 'test_images_cropped', 'util.py', 'view_finding']", 'stars': 0, 'watchers': 0, 'forks': 0, 'deprepos': 0, 'deppacks': 0}