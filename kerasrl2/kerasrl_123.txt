{'dependent': 'kerasrl', 'repo': '/anhdhbn/yolov3', 'language': 'Python', 'description': None, 'readme': '\n## üÜï Are you looking for a new YOLOv3 implemented by TF2.0 ?\n\n>If you hate the fucking tensorflow1.x very much, no worries! I have implemented **a new YOLOv3 repo with TF2.0**, and also made a chinese blog on how to implement YOLOv3 object detector from scratch. <br>\n[code](https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/YOLOV3) | [blog](https://github.com/YunYang1994/cv-notebooks/blob/master/ai_algorithm/YOLOv3.md)  | [issue](https://github.com/YunYang1994/tensorflow-yolov3/issues/39)\n\n## part 1. Quick start\n1. Clone this file\n```bashrc\n$ git clone https://github.com/YunYang1994/tensorflow-yolov3.git\n```\n2.  You are supposed  to install some dependencies before getting out hands with these codes.\n```bashrc\n$ cd tensorflow-yolov3\n$ pip install -r ./docs/requirements.txt\n```\n3. Exporting loaded COCO weights as TF checkpoint(`yolov3_coco.ckpt`)„Äê[BaiduCloud](https://pan.baidu.com/s/11mwiUy8KotjUVQXqkGGPFQ&shfl=sharepset)„Äë\n```bashrc\n$ cd checkpoint\n$ wget https://github.com/YunYang1994/tensorflow-yolov3/releases/download/v1.0/yolov3_coco.tar.gz\n$ tar -xvf yolov3_coco.tar.gz\n$ cd ..\n$ python convert_weight.py\n$ python freeze_graph.py\n```\n4. Then you will get some `.pb` files in the root path.,  and run the demo script\n```bashrc\n$ python image_demo.py\n$ python video_demo.py # if use camera, set video_path = 0\n```\n<p align="center">\n    <img width="100%" src="https://user-images.githubusercontent.com/30433053/68088581-9255e700-fe9b-11e9-8672-2672ab398abe.jpg" style="max-width:100%;">\n    </a>\n</p>\n\n## part 2. Train your own dataset\nTwo files are required as follows:\n\n- [`dataset.txt`](https://raw.githubusercontent.com/YunYang1994/tensorflow-yolov3/master/data/dataset/voc_train.txt): \n\n```\nxxx/xxx.jpg 18.19,6.32,424.13,421.83,20 323.86,2.65,640.0,421.94,20 \nxxx/xxx.jpg 48,240,195,371,11 8,12,352,498,14\n# image_path x_min, y_min, x_max, y_max, class_id  x_min, y_min ,..., class_id \n# make sure that x_max < width and y_max < height\n```\n\n- [`class.names`](https://github.com/YunYang1994/tensorflow-yolov3/blob/master/data/classes/coco.names):\n\n```\nperson\nbicycle\ncar\n...\ntoothbrush\n```\n\n### 2.1 Train on VOC dataset\nDownload VOC PASCAL trainval  and test data\n```bashrc\n$ wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n$ wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n$ wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n```\nExtract all of these tars into one directory and rename them, which should have the following basic structure.\n\n```bashrc\n\nVOC           # path:  /home/yang/dataset/VOC\n‚îú‚îÄ‚îÄ test\n|    ‚îî‚îÄ‚îÄVOCdevkit\n|        ‚îî‚îÄ‚îÄVOC2007 (from VOCtest_06-Nov-2007.tar)\n‚îî‚îÄ‚îÄ train\n     ‚îî‚îÄ‚îÄVOCdevkit\n         ‚îî‚îÄ‚îÄVOC2007 (from VOCtrainval_06-Nov-2007.tar)\n         ‚îî‚îÄ‚îÄVOC2012 (from VOCtrainval_11-May-2012.tar)\n                     \n$ python scripts/voc_annotation.py --data_path /home/yang/test/VOC\n```\nThen edit your `./core/config.py` to make some necessary configurations\n\n```bashrc\n__C.YOLO.CLASSES                = "./data/classes/voc.names"\n__C.TRAIN.ANNOT_PATH            = "./data/dataset/voc_train.txt"\n__C.TEST.ANNOT_PATH             = "./data/dataset/voc_test.txt"\n```\nHere are two kinds of training method: \n\n##### (1) train from scratch:\n\n```bashrc\n$ python train.py\n$ tensorboard --logdir ./data\n```\n##### (2) train from COCO weights(recommend):\n\n```bashrc\n$ cd checkpoint\n$ wget https://github.com/YunYang1994/tensorflow-yolov3/releases/download/v1.0/yolov3_coco.tar.gz\n$ tar -xvf yolov3_coco.tar.gz\n$ cd ..\n$ python convert_weight.py --train_from_coco\n$ python train.py\n```\n### 2.2 Evaluate on VOC dataset\n\n```\n$ python evaluate.py\n$ cd mAP\n$ python main.py -na\n```\n\nthe mAP on the VOC2012 dataset:\n\n<p align="center">\n    <img width="50%" src="https://user-images.githubusercontent.com/33013904/58227054-dd4fc800-7d5b-11e9-85aa-67854292fbe0.png" style="max-width:50%;">\n    </a>\n</p>\n\n\n## part 3. Stargazers over time\n\n[![Stargazers over time](https://starcharts.herokuapp.com/YunYang1994/tensorflow-yolov3.svg)](https://starcharts.herokuapp.com/YunYang1994/tensorflow-yolov3)\n\n## part 4. Other Implementations\n\n[-**`YOLOv3ÁõÆÊ†áÊ£ÄÊµãÊúâ‰∫ÜTensorFlowÂÆûÁé∞ÔºåÂèØÁî®Ëá™Â∑±ÁöÑÊï∞ÊçÆÊù•ËÆ≠ÁªÉ`**](https://mp.weixin.qq.com/s/cq7g1-4oFTftLbmKcpi_aQ)<br>\n\n[-**`Stronger-yolo`**](https://github.com/Stinky-Tofu/Stronger-yolo)<br>\n\n[- **`Implementing YOLO v3 in Tensorflow (TF-Slim)`**](https://itnext.io/implementing-yolo-v3-in-tensorflow-tf-slim-c3c55ff59dbe)\n\n[- **`YOLOv3_TensorFlow`**](https://github.com/wizyoung/YOLOv3_TensorFlow)\n\n[- **`Object Detection using YOLOv2 on Pascal VOC2012`**](https://fairyonice.github.io/Part_1_Object_Detection_with_Yolo_for_VOC_2014_data_anchor_box_clustering.html)\n\n[-**`Understanding YOLO`**](https://hackernoon.com/understanding-yolo-f5a74bbc7967)\n\n', 'contents': "['.github', '.gitignore', 'LICENSE', 'LICENSE.fuck', 'README.md', 'checkpoint', 'convert_weight.py', 'core', 'data', 'docs', 'evaluate.py', 'freeze_graph.py', 'from_darknet_weights_to_ckpt.py', 'from_darknet_weights_to_pb.py', 'image_demo.py', 'mAP', 'requirements.txt', 'scripts', 'train.py', 'video_demo.py']", 'stars': 0, 'watchers': 0, 'forks': 0, 'deprepos': 0, 'deppacks': 0}