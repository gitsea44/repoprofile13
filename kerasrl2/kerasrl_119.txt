{'dependent': 'kerasrl', 'repo': '/upkoi/skypond', 'language': 'Python', 'description': None, 'readme': '<div align="center">\n  <img src="docs/images/logo.png" style="width:40%"><br>\n</div>\n\n# SkyPond - A Simple Platform for Reinforcement Learning Competitions\nSkyPond is a simple MIT licensed execution engine for multi-agent reinforcement learning competitions and agent evaluation. It was developed by [Upkoi](https://upkoi.com) and is currently in use by [T[AI]L (Tampa AI League)](https://midnightfight.ai) for a recurring midnight reinforcement learning competition.\n\nWe think reinforcement learning competitions offer a great opportunity to learn (and are a lot of fun) and SkyPond offers much of the structure needed to build a game out of the box.\n\nThis project created from the core execution engine used by T[AI]L and we\'re working on abstracting away the main game to better allow additional games and more use cases. See [CONTRIBUTING.md](CONTRIBUTING.md) for more information.\n\n## Benefits\n- Compatibility with OpenAI Gym.\n- Support for Multiple Games (Create Your Own Game)\n- First-Class Shared Agent State Handling\n- Out of the Box Agent Execution in Docker\n- Support for Non-Docker Agents & Hybrid Agent Execution (Run Docker and Non-Docker Agents Together)\n- Self-Qualification for Submissions\n- Quick Prototyping Helpers for Reward and Multi-Agent Parameters\n\nSkyPond makes it straightforward for competitors to build and test reinforcement learning submissions. Submissions can be tested in a very similar execution model to the competition environment, improving the experience for competitors and competition organizers.\n\n## Requirements\n- Python 3\n- Full Docker Installation & Support (this excludes virtualized environments like Google Colaboratory)\n- Docker Python API\n- Ethereum API\n- Profanity\n- Numpy\n- OpenAI Gym\n- TQDM\n\n## Installation\nClone the repository and use the setup tool to install:\n\nsudo python3 setup.py install\n\n## Contributing\nWe\'re accepting bug fixes and performance improvements. See [CONTRIBUTING.md](CONTRIBUTING.md) for more information.\n\n## Development Roadmap\nWe think there is a bright future for reinforcement learning competitions and hope to provide helpful tools to make them more accessible to set up and run.\n\nThis library is currently being tested by T[AI]L - an experimental reinforcement learning competition - and will likely undergo structural changes in response.\n\nAt the moment this library is biased towards T[AI]L and -a starting agent - Four Keys. Eventually, we hope to make the library sufficiently generic and open up support for game submissions. In general, as we identify useful features in T[AI]L we plan to make them generic and bring them over to SkyPond.\n\n## Contact\nPlease reach out to rob@upkoi.com for any questions or comments.\n\n## Acknowledgments\nThe idea of using a docker instance for the agent in this project came from Pommerman and Duckietown at NeurIPS 2018. The initial game, Four Keys, is heavily influenced by the starting grid world environments offered by OpenAI Gym as well as the fantastic MiniGrid environment. Lastly, the core PPO engine provided in the RL example builds on top of the Torch AC library.\n\n* [Pommerman](https://github.com/MultiAgentLearning/playground)\n* [Duckietown](https://github.com/duckietown)\n* [OpenAI Gym](https://github.com/openai/gym)\n* [MiniGrid](https://github.com/maximecb/gym-minigrid)\n* [Torch AC](https://github.com/lcswillems/torch-ac)\n', 'contents': "['.gitignore', 'CONTRIBUTING.md', 'LICENSE', 'README.md', 'docker_image', 'docs', 'pytest.ini', 'setup.cfg', 'setup.py', 'skypond', 'tests']", 'stars': 0, 'watchers': 0, 'forks': 2, 'deprepos': 0, 'deppacks': 0}